---
title: "Report on the Alien Analysis"
author: "Riccardo Fusaroli"
date: "14 May 2020"
output: html_document
---

# Hypotheses

H1. Groups will outperform individuals in the training sessions across levels of complexity.
H2. Groups will outperform individuals in abstraction levels
H2a. Groups will outperform individuals in the transfer task across levels of complexity. 
H2b. Groups will outperform individuals in the first cycle of each session (before any tokens get repeated).
H3. Variability in group performance will be contingent on semantic distance


# Load libraries and data
# Define correct data types

```{r LibrariesData, echo=F, warning=F, message=F}

# Load libraries and data
pacman::p_load(
  tidyverse,
  brms,
  here,
  viridis,
  bayesplot
)
color_scheme_set("viridis")

setwd(here())

# Load the performance data and ensure the data structure is right

d <- read_csv(here("data","AlienData.txt")) %>%
  mutate(
    condition = factor(condition, levels=c("1", "2"), labels=c("Dyads", "Individuals")),
    subject = as.factor(ifelse(condition=='Dyads', subject + 30, subject)),
    session = as.numeric(session),
    cycle = as.numeric(ifelse(cycle == 0, 4, cycle)),
    trial = as.numeric(trial),
    test = as.factor(test),
    stimulus = as.factor(paste(stimulus,session)),
    category = as.factor(category),
    response = as.factor(response),
    dangerous = as.factor(dangerous),
    nutricious = as.factor(nutricious),
    correct = as.factor(correct),
    cumulative = as.numeric(cumulative),
    RT = as.numeric(RT),
    condition = relevel(condition, "Individuals")
  )



dSurvey <- read_delim(here("data", "AlienSurvey.txt"), delim = " ") %>%
  mutate(
    Subject = as.factor(Subject),
    Condition = as.factor(Condition)
  )



```


## Analysis 1 - Performance (correctness) as a function of condition (individual vs dyad) and complexity (session) in the training sessions

We use a mixed logistic regression model to assess main effects of condition (pair vs. individual) and complexity (session 1 to 3). We account for individual variability (random intercept plus random slopes due to session) and stimulus variability (random intercepts).
Hypothesis testing is on the %

### The first model tests main effects

```{r TrainingMainEffects, echo=F, warning=F, message=F}

d1 <- d %>% 
  subset(test == 0)

H1_f <- bf(
  correct ~ 0 + condition + condition:mo(session) + 
    (0 + condition + condition:mo(session) | subject) + 
    (0 + condition | stimulus)
)

get_prior(H1_f, d1, family = bernoulli)


H1_prior <- c(
  prior(normal(0, 1), class = b),
  prior(normal(0,.5), class = b, coef = "conditionDyads:mosession"),
  prior(normal(0,.5), class = b, coef = "conditionIndividuals:mosession"),
  prior(lkj(5), class = cor),
  prior(normal(0, .3), class = sd)
)

H1_m_prior <- brm(
  H1_f, 
  d1, 
  family = bernoulli,
  prior = H1_prior,
  sample_prior = "only",
  chains = 2,
  cores = 2,
  file = here("models","H1_m_prior"),
  control = list(adapt_delta=0.9, max_treedepth=20)
  )

## Checking prior predictions. Looks good
LogOddsPreds <- posterior_linpred(H1_m_prior)
rethinking::dens(
  inv_logit_scaled(LogOddsPreds[1:2000,])
)

H1_m <- brm(
  H1_f, 
  d1, 
  family = bernoulli,
  prior = H1_prior,
  sample_prior = TRUE,
  chains = 2,
  cores = 2,
  iter = 4000,
  file = here("models","H1_m1"),
  control = list(adapt_delta=0.9, max_treedepth=20)
  )

### Let's check model quality
summary(H1_m)  ## Any warnings?
LogOddsPreds <- posterior_linpred(H1_m)
rethinking::dens(
  inv_logit_scaled(LogOddsPreds[1:4000,])
)

## The markov chains (raw and ranked) have to look like they mixed well (overlapped)
color_scheme_set("viridis")
mcmc_trace(H1_m,
           pars = c("b_conditionIndividuals", "b_conditionDyads",
                    "bsp_conditionIndividuals:mosession", "bsp_conditionDyads:mosession",
           "sd_subject__conditionIndividuals", "sd_subject__conditionDyads",
           "sd_subject__conditionIndividuals:mosession","sd_subject__conditionDyads:mosession",
           "sd_stimulus__conditionIndividuals", "sd_stimulus__conditionDyads")) + 
  theme_classic()

mcmc_rank_overlay(H1_m,
                  pars = c("b_conditionIndividuals", "b_conditionDyads",
                    "bsp_conditionIndividuals:mosession", "bsp_conditionDyads:mosession",
           "sd_subject__conditionIndividuals", "sd_subject__conditionDyads",
           "sd_subject__conditionIndividuals:mosession","sd_subject__conditionDyads:mosession",
           "sd_stimulus__conditionIndividuals", "sd_stimulus__conditionDyads")) + theme_classic()

# The posteriors have to have moved and gotten more confident than the priors
p1 <- plot(hypothesis(H1_m,"conditionIndividuals > 0"))[[1]]
p2 <- plot(hypothesis(H1_m,"conditionDyads > 0"))[[1]]
p3 <- plot(hypothesis(H1_m,"conditionIndividuals > 0", class="sd", group="subject"))
p4 <- plot(hypothesis(H1_m,"conditionDyads > 0", class="sd", group="subject"))
p5 <- plot(hypothesis(H1_m,"conditionIndividuals > 0", class="sd", group="stimulus"))
p6 <- plot(hypothesis(H1_m,"conditionDyads > 0", class="sd", group="stimulus"))
p7 <- plot(hypothesis(H1_m,"conditionIndividuals:mosession > 0", class="bsp"))
p8 <- plot(hypothesis(H1_m,"conditionDyads:mosession > 0", class="bsp"))
p9 <- plot(hypothesis(H1_m,"conditionDyads:mosession > conditionIndividuals:mosession", class="bsp"))
p10 <- plot(hypothesis(H1_m,"conditionIndividuals:mosession > 0", class="sd", group="subject"))
p11 <- plot(hypothesis(H1_m,"conditionDyads:mosession > 0", class="sd", group="subject"))

## Hypothesis testing
## Performance is best for dyads

Post <- posterior_samples(H1_m, pars = c(
  "b_conditionIndividuals", "b_conditionDyads",
  "bsp_conditionIndividuals:mosession", "bsp_conditionDyads:mosession",
  "simo_conditionIndividuals:mosession1","simo_conditionDyads:mosession1")) %>%
  mutate(
    IndividualsS1 = inv_logit_scaled(b_conditionIndividuals),
    IndividualsS2 = inv_logit_scaled(b_conditionIndividuals + 
                                       2 * `simo_conditionIndividuals:mosession1[1]` *
                                       `bsp_conditionIndividuals:mosession`),
    IndividualsS3 = inv_logit_scaled(b_conditionIndividuals + 
                                       2 * `simo_conditionIndividuals:mosession1[1]` *
                                       `bsp_conditionIndividuals:mosession`+  
                                       2 * `simo_conditionIndividuals:mosession1[2]` *
                                       `bsp_conditionIndividuals:mosession`),
    DyadsS1 = inv_logit_scaled(b_conditionDyads),
    DyadsS2 = inv_logit_scaled(b_conditionDyads + 
                                       2 * `simo_conditionDyads:mosession1[1]` *
                                       `bsp_conditionDyads:mosession`),
    DyadsS3 = inv_logit_scaled(b_conditionDyads + 
                                       2 * `simo_conditionDyads:mosession1[1]` *
                                       `bsp_conditionDyads:mosession` +  
                                       2 * `simo_conditionIndividuals:mosession1[2]` *
                                       `bsp_conditionDyads:mosession`),
    H1 = (DyadsS1 + DyadsS2 + DyadsS3)/3 - (IndividualsS1 + IndividualsS2 + IndividualsS3)/3,
    H2 = (DyadsS1 - DyadsS3) - (IndividualsS1 - IndividualsS3)
    )

H1_test <- paste0("B = ", round(mean(Post$H1, na.rm = T), 2) * 100, 
               ", SE = ", round(sd(Post$H1, na.rm = T), 2) * 100, 
               ", 95% CI's = ", round(quantile(Post$H1, .025)[[1]], 2) * 100, 
               " ", round(quantile(Post$H1, .975)[[1]],2)  * 100,
               ", ER = ", round(sum(Post$H1 > 0)/sum(Post$H1 <= 0), 2),
               ", credibility = ", round(sum(Post$H1 > 0)/nrow(Post), 2) * 100)
round(mean((Post$DyadsS1 + Post$DyadsS2 + Post$DyadsS3)/3),2)*100
round(sd((Post$DyadsS1 + Post$DyadsS2 + Post$DyadsS3)/3),2)*100
round(quantile((Post$DyadsS1 + Post$DyadsS2 + Post$DyadsS3)/3, c(.025, 0.975)),2)*100
round(mean((Post$IndividualsS1 + Post$IndividualsS2 + Post$IndividualsS3)/3),2)*100
round(sd((Post$IndividualsS1 + Post$IndividualsS2 + Post$IndividualsS3)/3),2)*100
round(quantile((Post$IndividualsS1 + Post$IndividualsS2 + Post$IndividualsS3)/3, c(.025, 0.975)),2)*100


H2_test <- paste0("B = ", round(mean(Post$H2, na.rm = T), 2) * 100, 
               ", SE = ", round(sd(Post$H2, na.rm = T), 2) * 100, 
               ", 95% CI's = ", round(quantile(Post$H2, .025)[[1]], 2) * 100, 
               " ", round(quantile(Post$H2, .975)[[1]],2)  * 100,
               ", ER = ", round(sum(Post$H2 > 0)/sum(Post$H2 <= 0), 2),
               ", credibility = ", round(sum(Post$H2 > 0)/nrow(Post), 2) * 100)

summary(Post$DyadsS1 - Post$DyadsS3)
summary(Post$IndividualsS1 - Post$IndividualsS3)
round(mean(Post$DyadsS1 - Post$DyadsS3),2)*100
round(sd(Post$DyadsS1 - Post$DyadsS3),2)*100
round(quantile(Post$DyadsS1 - Post$DyadsS3, c(.025, 0.975)),2)*100
round(mean(Post$DyadsS1),2)*100
round(sd(Post$DyadsS1),2)*100
round(quantile(Post$DyadsS1, c(.025, 0.975)),2)*100
round(mean(Post$DyadsS2),2)*100
round(sd(Post$DyadsS2),2)*100
round(quantile(Post$DyadsS2, c(.025, 0.975)),2)*100
round(mean(Post$DyadsS3),2)*100
round(sd(Post$DyadsS3),2)*100
round(quantile(Post$DyadsS3, c(.025, 0.975)),2)*100

round(mean(Post$IndividualsS1 - Post$IndividualsS3),2)*100
round(sd(Post$IndividualsS1 - Post$IndividualsS3),2)*100
round(quantile(Post$IndividualsS1 - Post$IndividualsS3, c(.025, 0.975)),2)*100
round(mean(Post$IndividualsS1),2)*100
round(sd(Post$IndividualsS1),2)*100
round(quantile(Post$IndividualsS1, c(.025, 0.975)),2)*100
round(mean(Post$IndividualsS2),2)*100
round(sd(Post$IndividualsS2),2)*100
round(quantile(Post$IndividualsS2, c(.025, 0.975)),2)*100
round(mean(Post$IndividualsS3),2)*100
round(sd(Post$IndividualsS3),2)*100
round(quantile(Post$IndividualsS3, c(.025, 0.975)),2)*100

## Plotting
plot(conditional_effects(H1_m), plot = FALSE)[[3]] + 
  scale_x_continuous(breaks=c(1, 2, 3)) + 
  theme_classic()

d1$Accuracy <- as.numeric(d1$correct)-1
dd <- d1 %>% mutate(correct = predict(H1_m)[,1]) %>%
  group_by(subject, condition, session) %>%
  summarize(Accuracy1 = mean(correct, na.rm=T),
            Accuracy2 = mean(Accuracy, na.rm=T))

Fig2 <- ggplot(dd) + 
  geom_smooth(aes(session, Accuracy1, color = condition), method = "scam", 
        formula = y ~ s(x, k = 8, bs = "mpd"), 
        se = T) +
  geom_line(aes(session, Accuracy2, group=subject, color = condition), alpha=0.3) + 
  scale_x_continuous(breaks=c(1, 2, 3)) + 
  ylab("Training Performance") + 
  theme_classic()

ggsave(here("plots","Figure2.svg"), Fig2, height=10, width=10)

```



### Hypothesis 2a - Test Performance (correctness) as a function of condition (individual vs dyad) and complexity (session)


```{r Test, echo=F, warning=F, message=F}

d2 <- subset(d, test == 1)

H2a_f <- bf(
  correct ~ 0 + condition + condition:mo(session) + 
    (0 + condition + condition:mo(session) | subject) + 
    (0 + condition  | stimulus)
)

get_prior(H2a_f, d2, family = bernoulli)


H2a_prior <- c(
  prior(normal(0, 1), class = b),
  prior(normal(0,.5), class = b, coef = "conditionDyads:mosession"),
  prior(normal(0,.5), class = b, coef = "conditionIndividuals:mosession"),
  prior(lkj(5), class = cor),
  prior(normal(0, 1), class = sd)
)

H2a_m_prior <- brm(
  H2a_f, 
  d2, 
  family = bernoulli,
  prior = H2a_prior,
  sample_prior = "only",
  chains = 2,
  cores = 2,
  file = here("models","H2a_m_prior"),
  control = list(adapt_delta=0.9, max_treedepth=20)
  )

## Checking prior predictions. Looks good
LogOddsPreds <- posterior_linpred(H2a_m_prior)
rethinking::dens(
  inv_logit_scaled(LogOddsPreds[1:2000,])
)

H2a_m <- brm(
  H2a_f, 
  d2, 
  family = bernoulli,
  prior = H2_prior,
  sample_prior = TRUE,
  chains = 2,
  cores = 2,
  iter = 4000,
  file = here("models","H2a_m"),
  control = list(adapt_delta=0.9, max_treedepth=20)
  )

### Let's check model quality
summary(H2a_m)  ## Any warnings?
LogOddsPreds <- posterior_linpred(H2a_m)
rethinking::dens(
  inv_logit_scaled(LogOddsPreds[1:2000,])
) # Any obvious bias?

## The markov chains (raw and ranked) have to look like they mixed well (overlapped)
mcmc_trace(H2a_m,
           pars = c("b_conditionIndividuals", "b_conditionDyads",
                    "bsp_conditionIndividuals:mosession", "bsp_conditionDyads:mosession",
           "sd_subject__conditionIndividuals", "sd_subject__conditionDyads",
           "sd_subject__conditionIndividuals:mosession","sd_subject__conditionDyads:mosession",
           "sd_stimulus__conditionIndividuals", "sd_stimulus__conditionDyads")) + 
  theme_classic()

mcmc_rank_overlay(H2a_m,
                  pars = c("b_conditionIndividuals", "b_conditionDyads",
                    "bsp_conditionIndividuals:mosession", "bsp_conditionDyads:mosession",
           "sd_subject__conditionIndividuals", "sd_subject__conditionDyads",
           "sd_subject__conditionIndividuals:mosession","sd_subject__conditionDyads:mosession",
           "sd_stimulus__conditionIndividuals", "sd_stimulus__conditionDyads")) + theme_classic()

# The posteriors have to have moved and gotten more confident than the priors
plot(hypothesis(H2a_m,"conditionIndividuals > 0"))
plot(hypothesis(H2a_m,"conditionDyads > 0"))
plot(hypothesis(H2a_m,"conditionIndividuals > 0", class="sd", group="subject"))
plot(hypothesis(H2a_m,"conditionDyads > 0", class="sd", group="subject"))
plot(hypothesis(H2a_m,"conditionIndividuals > 0", class="sd", group="stimulus"))
plot(hypothesis(H2a_m,"conditionDyads > 0", class="sd", group="stimulus"))
plot(hypothesis(H2a_m,"conditionIndividuals:mosession > 0", class="bsp"))
plot(hypothesis(H2a_m,"conditionDyads:mosession > 0", class="bsp"))
plot(hypothesis(H2a_m,"conditionDyads:mosession > conditionIndividuals:mosession", class="bsp"))
plot(hypothesis(H2a_m,"conditionIndividuals:mosession > 0", class="sd", group="subject"))
plot(hypothesis(H2a_m,"conditionDyads:mosession > 0", class="sd", group="subject"))

## Hypothesis testing
Post <- posterior_samples(H2a_m, pars = c(
  "b_conditionIndividuals", "b_conditionDyads",
  "bsp_conditionIndividuals:mosession", "bsp_conditionDyads:mosession",
  "simo_conditionIndividuals:mosession1","simo_conditionDyads:mosession1")) %>%
  mutate(
    IndividualsS1 = inv_logit_scaled(b_conditionIndividuals),
    IndividualsS2 = inv_logit_scaled(b_conditionIndividuals + 
                                       2 * `simo_conditionIndividuals:mosession1[1]` *
                                       `bsp_conditionIndividuals:mosession`),
    IndividualsS3 = inv_logit_scaled(b_conditionIndividuals + 
                                       2 * `simo_conditionIndividuals:mosession1[1]` *
                                       `bsp_conditionIndividuals:mosession`+  
                                       2 * `simo_conditionIndividuals:mosession1[2]` *
                                       `bsp_conditionIndividuals:mosession`),
    DyadsS1 = inv_logit_scaled(b_conditionDyads),
    DyadsS2 = inv_logit_scaled(b_conditionDyads + 
                                       2 * `simo_conditionDyads:mosession1[1]` *
                                       `bsp_conditionDyads:mosession`),
    DyadsS3 = inv_logit_scaled(b_conditionDyads + 
                                       2 * `simo_conditionDyads:mosession1[1]` *
                                       `bsp_conditionDyads:mosession` +  
                                       2 * `simo_conditionIndividuals:mosession1[2]` *
                                       `bsp_conditionDyads:mosession`),
    H1 = (DyadsS1 + DyadsS2 + DyadsS3)/3 - (IndividualsS1 + IndividualsS2 + IndividualsS3)/3,
    H2 = (IndividualsS1 - IndividualsS3) - (DyadsS1 - DyadsS3) 
    )

H1_test <- paste0("B = ", round(mean(Post$H1, na.rm = T), 2) * 100, 
               ", SE = ", round(sd(Post$H1, na.rm = T), 2) * 100, 
               ", 95% CI's = ", round(quantile(Post$H1, .025)[[1]], 2) * 100, 
               " ", round(quantile(Post$H1, .975)[[1]],2)  * 100,
               ", ER = ", round(sum(Post$H1 > 0)/sum(Post$H1 <= 0), 2),
               ", credibility = ", round(sum(Post$H1 > 0)/nrow(Post), 2) * 100)

round(mean((Post$DyadsS1 + Post$DyadsS2 + Post$DyadsS3)/3),2)*100
round(sd((Post$DyadsS1 + Post$DyadsS2 + Post$DyadsS3)/3),2)*100
round(quantile((Post$DyadsS1 + Post$DyadsS2 + Post$DyadsS3)/3, c(.025, 0.975)),2)*100
round(mean((Post$IndividualsS1 + Post$IndividualsS2 + Post$IndividualsS3)/3),2)*100
round(sd((Post$IndividualsS1 + Post$IndividualsS2 + Post$IndividualsS3)/3),2)*100
round(quantile((Post$IndividualsS1 + Post$IndividualsS2 + Post$IndividualsS3)/3, c(.025, 0.975)),2)*100


H2_test <- paste0("B = ", round(mean(Post$H2, na.rm = T), 2) * 100, 
               ", SE = ", round(sd(Post$H2, na.rm = T), 2) * 100, 
               ", 95% CI's = ", round(quantile(Post$H2, .025)[[1]], 2) * 100, 
               " ", round(quantile(Post$H2, .975)[[1]],2)  * 100,
               ", ER = ", round(sum(Post$H2 > 0)/sum(Post$H2 <= 0), 2),
               ", credibility = ", round(sum(Post$H2 > 0)/nrow(Post), 2) * 100)

summary(Post$DyadsS1 - Post$DyadsS3)
summary(Post$IndividualsS1 - Post$IndividualsS3)
round(mean(Post$DyadsS1 - Post$DyadsS3),2)*100
round(sd(Post$DyadsS1 - Post$DyadsS3),2)*100
round(quantile(Post$DyadsS1 - Post$DyadsS3, c(.025, 0.975)),2)*100
round(mean(Post$DyadsS1),2)*100
round(sd(Post$DyadsS1),2)*100
round(quantile(Post$DyadsS1, c(.025, 0.975)),2)*100
round(mean(Post$DyadsS2),2)*100
round(sd(Post$DyadsS2),2)*100
round(quantile(Post$DyadsS2, c(.025, 0.975)),2)*100
round(mean(Post$DyadsS3),2)*100
round(sd(Post$DyadsS3),2)*100
round(quantile(Post$DyadsS3, c(.025, 0.975)),2)*100

round(mean(Post$IndividualsS1 - Post$IndividualsS3),2)*100
round(sd(Post$IndividualsS1 - Post$IndividualsS3),2)*100
round(quantile(Post$IndividualsS1 - Post$IndividualsS3, c(.025, 0.975)),2)*100
round(mean(Post$IndividualsS1),2)*100
round(sd(Post$IndividualsS1),2)*100
round(quantile(Post$IndividualsS1, c(.025, 0.975)),2)*100
round(mean(Post$IndividualsS2),2)*100
round(sd(Post$IndividualsS2),2)*100
round(quantile(Post$IndividualsS2, c(.025, 0.975)),2)*100
round(mean(Post$IndividualsS3),2)*100
round(sd(Post$IndividualsS3),2)*100
round(quantile(Post$IndividualsS3, c(.025, 0.975)),2)*100

## Plotting
plot(conditional_effects(H2_m), plot = FALSE)[[3]] + 
  scale_x_continuous(breaks=c(1, 2, 3)) + 
  #ylim(.25, 1) +
  theme_classic()

d2$Accuracy <- as.numeric(d2$correct)-1
dd <- d2 %>% mutate(correct = as.numeric(correct)-1) %>%
  group_by(subject, condition, session) %>%
  summarize(Accuracy = mean(correct, na.rm=T))

ggplot(dd, aes(session, Accuracy, color = condition)) + 
  geom_smooth(method = "scam", 
        formula = y ~ s(x, k = 8, bs = "mpd"), 
        se = T) +
  geom_line(aes(group=subject, color = condition), alpha=0.3) + 
  scale_x_continuous(breaks=c(1, 2, 3)) + 
  theme_classic()

ggplot(d2, aes(session, Accuracy, color = condition)) +
  geom_smooth(method = "scam", 
        formula = y ~ s(x, k = 4, bs = "mpd"), 
        se = T) +
  stat_smooth(geom='line',aes(group = subject), alpha=0.2, method = "scam", 
        formula = y ~ s(x, k = 4, bs = "mpd"), 
        se = F) +
  scale_x_continuous(breaks=c(1, 2, 3)) + 
  theme_classic()


## Performance at session 1 is best for dyads
hypothesis(H2a_m,"conditionDyads > conditionIndividuals", class="b")
## Decrease in performance by session is smaller for dyads
hypothesis(H2a_m,"conditionDyads:mosession > conditionIndividuals:mosession", class="bsp")
hypothesis(H2a_m,"conditionDyads:mosession < 0", class="bsp")
hypothesis(H2a_m,"conditionIndividuals:mosession < 0", class="bsp")

## Plotting
plot(conditional_effects(H2a_m), plot = FALSE)[[3]] + theme_classic()
d2$Accuracy <- as.numeric(d2$correct)-1
ggplot(d2, aes(session,Accuracy, color = condition)) +
  geom_smooth(method = "scam", 
        formula = y ~ s(x, k = 5, bs = "mpd"), 
        se = T) +
  stat_smooth(geom='line',aes(group = subject), alpha=0.3, method = "scam", 
        formula = y ~ s(x, k = 5, bs = "mpd"), 
        se = F) +
  theme_classic()
```

## H2b 

```{r}
### Now only first cycle
H2b_m <- brm(
  H2b_f, 
  subset(d1, cycle==1), 
  family = bernoulli,
  prior = H2b_prior,
  sample_prior = TRUE,
  chains = 2,
  cores = 2,
  iter = 4000,
  file = here("models","H2b_m"),
  control = list(adapt_delta=0.9, max_treedepth=20)
  )

H2b_m  <- add_criterion(H2b_m, criterion = c("loo", "bayes_R2"))

### Let's check model quality
summary(H2b_m)  ## Any warnings?
LogOddsPreds <- posterior_linpred(H2b_m)
rethinking::dens(
  inv_logit_scaled(LogOddsPreds[1:2000,])
) # Any obvious bias?

## The markov chains (raw and ranked) have to look like they mixed well (overlapped)
mcmc_trace(H2b_m,
           pars = c("b_conditionIndividuals", "b_conditionDyads",
                    "bsp_conditionIndividuals:mosession", "bsp_conditionDyads:mosession",
                    "bsp_conditionIndividuals:motrial", "bsp_conditionDyads:motrial",
                    "bsp_conditionIndividuals:mosession:motrial", "bsp_conditionDyads:mosession:motrial",
           "sd_subject__conditionIndividuals", "sd_subject__conditionDyads",
           "sd_subject__conditionIndividuals:mosession","sd_subject__conditionDyads:mosession",
           "sd_subject__conditionIndividuals:motrial","sd_subject__conditionDyads:motrial",
           "sd_subject__conditionIndividuals:mosession:motrial","sd_subject__conditionDyads:mosession:motrial",
           "sd_stimulus__conditionIndividuals", "sd_stimulus__conditionDyads")) + 
  theme_classic()

mcmc_rank_overlay(H2b_m,
                  pars = c("b_conditionIndividuals", "b_conditionDyads",
                    "bsp_conditionIndividuals:mosession", "bsp_conditionDyads:mosession",
                    "bsp_conditionIndividuals:mosession:motrial", "bsp_conditionDyads:mosession:motrial",
           "sd_subject__conditionIndividuals", "sd_subject__conditionDyads",
           "sd_subject__conditionIndividuals:mosession","sd_subject__conditionDyads:mosession",
           "sd_subject__conditionIndividuals:motrial","sd_subject__conditionDyads:motrial",
           "sd_subject__conditionIndividuals:mosession:motrial","sd_subject__conditionDyads:mosession:motrial",
           "sd_stimulus__conditionIndividuals", "sd_stimulus__conditionDyads")) + theme_classic()

# The posteriors have to have moved and gotten more confident than the priors
plot(hypothesis(H2b_m,"conditionIndividuals > 0"))
plot(hypothesis(H2b_m,"conditionDyads > 0"))
plot(hypothesis(H2b_m,"conditionIndividuals:mosession > 0", class = "bsp"))
plot(hypothesis(H2b_m,"conditionDyads:mosession > 0", class = "bsp"))
plot(hypothesis(H2b_m,"conditionIndividuals:motrial > 0", class = "bsp"))
plot(hypothesis(H2b_m,"conditionDyads:motrial > 0", class = "bsp"))
plot(hypothesis(H2b_m,"conditionIndividuals:mosession:motrial > 0", class="bsp"))
plot(hypothesis(H2b_m,"conditionDyads:mosession:motrial > 0", class="bsp"))

plot(hypothesis(H2b_m,"conditionIndividuals > 0", class="sd", group="subject"))
plot(hypothesis(H2b_m,"conditionDyads > 0", class="sd", group="subject"))
plot(hypothesis(H2b_m,"conditionIndividuals:mosession > 0", class="sd", group="subject"))
plot(hypothesis(H2b_m,"conditionDyads:mosession > 0", class="sd", group="subject"))
plot(hypothesis(H2b_m,"conditionIndividuals:motrial > 0", class="sd", group="subject"))
plot(hypothesis(H2b_m,"conditionDyads:motrial > 0", class="sd", group="subject"))
plot(hypothesis(H2b_m,"conditionIndividuals:mosession:motrial > 0", class="sd", group="subject"))
plot(hypothesis(H2b_m,"conditionDyads:mosession:motrial > 0", class="sd", group="subject"))
plot(hypothesis(H2b_m,"conditionIndividuals > 0", class="sd", group="stimulus"))
plot(hypothesis(H2b_m,"conditionDyads > 0", class="sd", group="stimulus"))

## Hypothesis testing

### Dyads learn quicker than individuals
### Dyads learning decreases less than individuals
Post <- posterior_samples(H2b_m, pars = c(
  "b_conditionIndividuals", "b_conditionDyads",
  "bsp_conditionIndividuals:mosession", "bsp_conditionDyads:mosession",
  "simo_conditionIndividuals:mosession","simo_conditionDyads:mosession",
  "bsp_conditionIndividuals:motrial", "bsp_conditionDyads:motrial",
  "simo_conditionIndividuals:motrial","simo_conditionDyads:motrial",
  "bsp_conditionIndividuals:mosession:motrial", "bsp_conditionDyads:mosession:motrial",
  "simo_conditionIndividuals:mosession:motrial", "simo_conditionDyads:mosession:motrial")) 

Post <- Post %>% mutate(
  IndividualFinalS1 = inv_logit_scaled(`b_conditionIndividuals` + 32 * `bsp_conditionIndividuals:motrial`),
  DyadFinalS1 = inv_logit_scaled(`b_conditionDyads` + 32 * `bsp_conditionDyads:motrial`),
  IndividualFinalS2 = inv_logit_scaled(`b_conditionIndividuals` + 
                       2 * `simo_conditionIndividuals:mosession1[1]` *
                                       `bsp_conditionIndividuals:mosession` + 
                       32 * 
                       (`bsp_conditionIndividuals:motrial` + 
                       `bsp_conditionIndividuals:mosession:motrial`
                       )),
  DyadFinalS2 = inv_logit_scaled(`b_conditionDyads` + 
                       2 * `simo_conditionDyads:mosession1[1]` *
                                       `bsp_conditionDyads:mosession` + 
                       32 * 
                       (`bsp_conditionDyads:motrial` + 
                       `bsp_conditionDyads:mosession:motrial`
                       )),
  IndividualFinalS3 = inv_logit_scaled(`b_conditionIndividuals` + 
                       3 * `bsp_conditionIndividuals:mosession` + 
                       32 * 
                       (`bsp_conditionIndividuals:motrial` + 
                       `bsp_conditionIndividuals:mosession:motrial`
                       )),
  DyadFinalS3 = inv_logit_scaled(`b_conditionDyads` + 
                       3 * `bsp_conditionDyads:mosession` + 
                       32 * 
                       (`bsp_conditionDyads:motrial` + 
                       `bsp_conditionDyads:mosession:motrial`
                       )),
  H3 = ((DyadFinalS1 + DyadFinalS2 + DyadFinalS3)/ 3) - ((IndividualFinalS1 + IndividualFinalS2 + IndividualFinalS3)/ 3),
  H3S1 = DyadFinalS1  - IndividualFinalS1, 
  H3S2 = DyadFinalS2  - IndividualFinalS2, 
  H3S3 = DyadFinalS3  - IndividualFinalS3,
  H4 = (DyadFinalS3  - IndividualFinalS3) - (DyadFinalS1  - IndividualFinalS1) 
)

H3_test <- paste0("B = ", round(mean(Post$H3, na.rm = T), 2) * 100, 
               ", SE = ", round(sd(Post$H3, na.rm = T), 2) * 100, 
               ", 95% CI's = ", round(quantile(Post$H3, .025)[[1]], 2) * 100, 
               " ", round(quantile(Post$H3, .975)[[1]],2)  * 100,
               ", ER = ", round(sum(Post$H3 > 0)/sum(Post$H3 <= 0), 2),
               ", credibility = ", round(sum(Post$H3 > 0)/nrow(Post), 2) * 100)

H3S1_test <- paste0("B = ", round(mean(Post$H3S1, na.rm = T), 2) * 100, 
               ", SE = ", round(sd(Post$H3S1, na.rm = T), 2) * 100, 
               ", 95% CI's = ", round(quantile(Post$H3S1, .025)[[1]], 2) * 100, 
               " ", round(quantile(Post$H3S1, .975)[[1]],2)  * 100,
               ", ER = ", round(sum(Post$H3S1 > 0)/sum(Post$H3S1 <= 0), 2),
               ", credibility = ", round(sum(Post$H3S1 > 0)/nrow(Post), 2) * 100)

H3S2_test <- paste0("B = ", round(mean(Post$H3S2, na.rm = T), 2) * 100, 
               ", SE = ", round(sd(Post$H3S2, na.rm = T), 2) * 100, 
               ", 95% CI's = ", round(quantile(Post$H3S2, .025)[[1]], 2) * 100, 
               " ", round(quantile(Post$H3S2, .975)[[1]],2)  * 100,
               ", ER = ", round(sum(Post$H3S2 > 0)/sum(Post$H3S2 <= 0), 2),
               ", credibility = ", round(sum(Post$H3S2 > 0)/nrow(Post), 2) * 100)

H3S3_test <- paste0("B = ", round(mean(Post$H3S3, na.rm = T), 2) * 100, 
               ", SE = ", round(sd(Post$H3S3, na.rm = T), 2) * 100, 
               ", 95% CI's = ", round(quantile(Post$H3S3, .025)[[1]], 2) * 100, 
               " ", round(quantile(Post$H3S3, .975)[[1]],2)  * 100,
               ", ER = ", round(sum(Post$H3S3 > 0)/sum(Post$H3S3 <= 0), 2),
               ", credibility = ", round(sum(Post$H3S3 > 0)/nrow(Post), 2) * 100)

H4_test <- paste0("B = ", round(mean(Post$H4, na.rm = T), 2) * 100, 
               ", SE = ", round(sd(Post$H4, na.rm = T), 2) * 100, 
               ", 95% CI's = ", round(quantile(Post$H4, .025)[[1]], 2) * 100, 
               " ", round(quantile(Post$H4, .975)[[1]],2)  * 100,
               ", ER = ", round(sum(Post$H4 > 0)/sum(Post$H4 <= 0), 2),
               ", credibility = ", round(sum(Post$H4 > 0)/nrow(Post), 2) * 100)

round(mean((Post$DyadFinalS1 + Post$DyadFinalS2 + Post$DyadFinalS3)/3),2)*100
round(sd((Post$DyadFinalS1 + Post$DyadFinalS2 + Post$DyadFinalS3)/3),2)*100
round(quantile((Post$DyadFinalS1 + Post$DyadFinalS2 + Post$DyadFinalS3)/3, c(.025, 0.975)),2)*100
round(mean((Post$IndividualFinalS1 + Post$IndividualFinalS2 + Post$IndividualFinalS3)/3),2)*100
round(sd((Post$IndividualFinalS1 + Post$IndividualFinalS2 + Post$IndividualFinalS3)/3),2)*100
round(quantile((Post$IndividualFinalS1 + Post$IndividualFinalS2 + Post$IndividualFinalS3)/3, c(.025, 0.975)),2)*100

round(mean((Post$DyadFinalS1)),2)*100
round(sd((Post$DyadFinalS1)),2)*100
round(quantile((Post$DyadFinalS1), c(.025, 0.975)),2)*100

round(mean((Post$DyadFinalS1 )),2)*100
round(sd((Post$DyadFinalS1 )),2)*100
round(quantile((Post$DyadFinalS1), c(.025, 0.975)),2)*100
round(mean((Post$DyadFinalS2 )),2)*100
round(sd((Post$DyadFinalS2 )),2)*100
round(quantile((Post$DyadFinalS2), c(.025, 0.975)),2)*100
round(mean((Post$DyadFinalS3 )),2)*100
round(sd((Post$DyadFinalS3 )),2)*100
round(quantile((Post$DyadFinalS3), c(.025, 0.975)),2)*100

round(mean((Post$IndividualFinalS1 )),2)*100
round(sd((Post$IndividualFinalS1 )),2)*100
round(quantile((Post$IndividualFinalS1), c(.025, 0.975)),2)*100
round(mean((Post$IndividualFinalS2 )),2)*100
round(sd((Post$IndividualFinalS2 )),2)*100
round(quantile((Post$IndividualFinalS2), c(.025, 0.975)),2)*100
round(mean((Post$IndividualFinalS3 )),2)*100
round(sd((Post$IndividualFinalS3 )),2)*100
round(quantile((Post$IndividualFinalS3), c(.025, 0.975)),2)*100

round(mean((Post$DyadFinalS1 - Post$DyadFinalS3)),2)*100
round(sd((Post$DyadFinalS1 - Post$DyadFinalS3)),2)*100
round(quantile((Post$DyadFinalS1 - Post$DyadFinalS3), c(.025, 0.975)),2)*100

round(mean((Post$IndividualFinalS1 - Post$IndividualFinalS3)),2)*100
round(sd((Post$IndividualFinalS1 - Post$IndividualFinalS3)),2)*100
round(quantile((Post$IndividualFinalS1 - Post$IndividualFinalS3), c(.025, 0.975)),2)*100

## PLOTTING
plot(conditional_effects(H2b_m), ask = FALSE)

Preds <- inv_logit_scaled(posterior_linpred(H2b_m))
d1a <- subset(d1, cycle==1)
d1a$AccuracyP <- Preds[1,]
d1a$Accuracy <- as.numeric(d1a$correct)-1

ggplot(d1a, aes(trial,AccuracyP,color=condition)) +
  geom_smooth(method = "scam", 
        formula = y ~ s(x, k = 5, bs = "mpi"), 
        se = T) +
  facet_wrap(.~session) +
  theme_classic()

ggplot(d1a, aes(trial,Accuracy, color = condition)) +
  geom_smooth(method = "scam", 
        formula = y ~ s(x, k = 5, bs = "mpi"), 
        se = T) +
  stat_smooth(geom='line',aes(group = subject), alpha=0.3, method = "scam", 
        formula = y ~ s(x, k = 5, bs = "mpi"), 
        se = F) +
  facet_wrap(.~session) +
  theme_classic()
```

## Hypothesis 3 - Semantic diversity predicts performance

```{r}
FinalData <- read_csv(here("data", "IndividualDifferences.csv"))

FinalData <- FinalData %>% mutate(
  Session = as.factor(Session),
  SemanticLevelTraining = 1 - SemanticLevelTraining)

## Now models
PerformanceTrainingSemanticLevelSession_f <- bf(
  PerformanceTrainingP ~ 0 + Session +  SemanticLevelTraining:Session + ( 1|Pair)
)

PerformanceTestSemanticLevelSession_f <- bf(
  PerformanceTestP ~ 0 + Session +  SemanticLevelTraining:Session + ( 1|Pair)
)

get_prior(PerformanceTrainingSemanticLevelSession_f, FinalData, family=gaussian)

prior <- c(
  prior(normal(0, 0.3), class = b),
  prior(normal(0, 0.5), class = sd),
  prior(normal(0, 0.5), class = sigma)
)

mSSemLvl <- brm(PerformanceTrainingSemanticLevelSession_f, 
                FinalData, chains=2, cores=2, 
                prior = prior,
                sample_prior = T,
                file = here("models", "PerformanceTrainingSemanticLevelSession"),
                control=list(adapt_delta=0.99))

mSSemLvl_T <- brm(PerformanceTestSemanticLevelSession_f, 
                FinalData, chains=2, cores=2, 
                prior = prior,
                sample_prior = T,
                file = here("models", "PerformanceTestSemanticLevelSession"),
                control=list(adapt_delta=0.99))

plot(hypothesis(mSSemLvl, "Session1 > 0"))
plot(hypothesis(mSSemLvl, "Session1:SemanticLevelTraining  > 0"))
plot(hypothesis(mSSemLvl, "Session2 > 0"))
plot(hypothesis(mSSemLvl, "Session2:SemanticLevelTraining  > 0"))
plot(hypothesis(mSSemLvl, "Session3 > 0"))
plot(hypothesis(mSSemLvl, "Session3:SemanticLevelTraining  > 0"))
plot(hypothesis(mSSemLvl, "Intercept  > 0", class="sd", group="Pair"))

plot(hypothesis(mSSemLvl_T, "Session1 > 0"))
plot(hypothesis(mSSemLvl_T, "Session1:SemanticLevelTraining  > 0"))
plot(hypothesis(mSSemLvl_T, "Session2 > 0"))
plot(hypothesis(mSSemLvl_T, "Session2:SemanticLevelTraining  > 0"))
plot(hypothesis(mSSemLvl_T, "Session3 > 0"))
plot(hypothesis(mSSemLvl_T, "Session3:SemanticLevelTraining  > 0"))
plot(hypothesis(mSSemLvl_T, "Intercept  > 0", class="sd", group="Pair"))

hypothesis(mSSemLvl, c(
  "(Session1:SemanticLevelTraining + Session2:SemanticLevelTraining + Session3:SemanticLevelTraining)/3  > 0", 
  "Session1:SemanticLevelTraining  > 0", 
           "Session2:SemanticLevelTraining  > 0",
           "Session3:SemanticLevelTraining  > 0"))
bayes_R2(mSSemLvl)
hypothesis(mSSemLvl_T, c(
  "(Session1:SemanticLevelTraining + Session2:SemanticLevelTraining + Session3:SemanticLevelTraining)/3  > 0", 
  "Session1:SemanticLevelTraining  > 0", 
           "Session2:SemanticLevelTraining  > 0",
           "Session3:SemanticLevelTraining  > 0"))


library(patchwork)
p1 <- ggplot(FinalData, 
             aes(SemanticLevelTraining, PerformanceTraining)) +
  geom_point() + geom_smooth(method=lm) + theme_classic()
p2 <- ggplot(FinalData, 
             aes(SemanticLevelTraining, PerformanceTest)) + 
  geom_point() + geom_smooth(method=lm) + theme_classic()
p1+p2

p1 <- ggplot(FinalData, 
             aes(SemanticLevelTraining, PerformanceTraining, color=Session, group=Session)) +
  geom_point() + geom_smooth(method=lm) + theme_classic()
p2 <- ggplot(FinalData, 
             aes(SemanticLevelTraining, PerformanceTest, color=Session, group=Session)) + 
  geom_point() + geom_smooth(method=lm) + theme_classic()
p1+p2


p1 <- plot(conditional_effects(mSSemLvl), plot=F, points=T)[[2]] + theme_classic()
p2 <- plot(conditional_effects(mSSemLvl_T), plot=F, points=T)[[2]] + theme_classic()
p1+p2
```

### Control Analyses - Controlling for differences in RT, effort and motivation by condition

```{r SurveyTest}
dSurvey <- dSurvey %>% mutate(
  Pair = ifelse(Condition=="Individual", Pair + 100, Pair)
)

Motivation_f <- bf(Motivation ~ 1 + Condition + (1 | gr(Pair, by=Condition)))

get_prior(Motivation_f, dSurvey, family = cumulative)

prior <- c(
  prior(normal(0, 1), class = b),
  prior(normal(0, 1), class = sd)
)

Motivation_m <- brm(Motivation_f, 
                    family = cumulative, 
                    chains = 2,
                    cores = 1,
                    prior = prior,
                    sample_prior = T,
                    control = list(adapt_delta=0.99, max_treedepth=20),
                    dSurvey)
plot(hypothesis(Motivation_m, "ConditionPair > 0"))
plot(hypothesis(Motivation_m, "Intercept:ConditionIndividual > 0", class="sd", group="Pair"))
plot(hypothesis(Motivation_m, "Intercept:ConditionPair > 0", class="sd", group="Pair"))

hypothesis(Motivation_m, "ConditionPair > 0")
conditional_effects(Motivation_m)
Effort_m <- brm(Effort ~ 1 + Condition + (1 | gr(Pair, by=Condition)), 
                family = cumulative, 
                    chains = 2,
                    cores = 1,
                    prior = prior,
                    sample_prior = T,
                    control = list(adapt_delta=0.99, max_treedepth=20),
                    dSurvey)
plot(hypothesis(Effort_m, "ConditionPair > 0"))
plot(hypothesis(Effort_m, "Intercept:ConditionIndividual > 0", class="sd", group="Pair"))
plot(hypothesis(Effort_m, "Intercept:ConditionPair > 0", class="sd", group="Pair"))
hypothesis(Effort_m, "ConditionPair > 0")
conditional_effects(Effort_m)

d <- d %>% mutate(session=as.factor(session))
RT_f <- bf(RT ~ 0 + condition:session + (0 + session | gr(subject, by=condition)) + 
    (0 + condition | stimulus))

get_prior(RT_f, d, family=shifted_lognormal())

prior <- c(
  prior(normal(8.7, 1), class = b),
  prior(lkj(5), class = cor),
  prior(normal(0, .1), class=sd)
)

RT_m <- brm(RT_f, d, 
            family = shifted_lognormal(),
            chains=2,
            cores=1,
            prior=prior,
            sample_prior=T,
                    control = list(adapt_delta=0.99, max_treedepth=20))
hypothesis(RT_m, "conditionIndividuals:session")

PerformanceTrainingEffortSession_f <- bf(
  PerformanceTrainingP ~ 0 + Session +  mo(Effort):Session + ( 1|Pair)
)
mTrainingSEffort <- brm(PerformanceTrainingEffortSession_f, FinalData, chains=2, cores=1, control=list(adapt_delta=0.99))
hypothesis(mTrainingSEffort, 
           c("(Session1:moEffort + Session2:moEffort + Session3:moEffort)/3  > 0", 
             "Session1:moEffort  > 0", 
           "Session2:moEffort  > 0",
           "Session3:moEffort  > 0"), class="bsp")

PerformanceTrainingMotivationSession_f <- bf(
  PerformanceTrainingP ~ 0 + Session +  mo(Motivation):Session + ( 1|Pair)
)
mTrainingSMotivation <- brm(PerformanceTrainingMotivationSession_f, FinalData, chains=2, cores=1, control=list(adapt_delta=0.99))
hypothesis(mTrainingSMotivation, 
           c("(Session1:moMotivation + Session2:moMotivation + Session3:moMotivation)/3  > 0",
           "Session1:moMotivation  > 0", 
           "Session2:moMotivation  > 0",
           "Session3:moMotivation  > 0"), class="bsp")

PerformanceTestEffortSession_f <- bf(
  PerformanceTestP ~ 0 + Session +  mo(Effort):Session + ( 1|Pair)
)
mTestSEffort <- brm(PerformanceTestEffortSession_f, FinalData, chains=2, cores=1, control=list(adapt_delta=0.99))

hypothesis(mTestSEffort, 
            c("(Session1:moEffort + Session2:moEffort + Session3:moEffort)/3  > 0", 
              "Session1:moEffort  > 0", 
            "Session2:moEffort  > 0",
            "Session3:moEffort  > 0"), class="bsp")
PerformanceTestMotivationSession_f <- bf(
  PerformanceTestP ~ 0 + Session +  mo(Motivation):Session + ( 1|Pair)
)
mTestSMotivation <- brm(PerformanceTestMotivationSession_f, FinalData, chains=2, cores=1, control=list(adapt_delta=0.99))

hypothesis(mTestSMotivation, 
           c("(Session1:moMotivation + Session2:moMotivation + Session3:moMotivation)/3  > 0",
           "Session1:moMotivation  > 0", 
           "Session2:moMotivation  > 0",
           "Session3:moMotivation  > 0"), class="bsp")

```