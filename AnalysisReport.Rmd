---
title: "Report on the Alien Analysis"
author: "Riccardo Fusaroli"
date: "11 Feb 2016"
output: html_document
---

- Analysis 1: training phase performance by condition and complexity (session)
- Analysis 2: test phase performance by condition and complexity (session)
- Analysis 3: learning curve analyses


# Define whether assumptions are tested (slow)
```{r Assumptions}
AssumptionTesting=F
```

# Load libraries and data
# Define correct data types

```{r LibrariesData, echo=F, warning=F, message=F}
# Load libraries and data
library(pacman)
p_load(lme4,MuMIn,ggplot2,influence.ME,boot,plyr,entropy,BayesFactor,broom,pastecs)

Data=read.table('AlienData.txt', sep=",", header=TRUE)
Data$condition=factor(Data$condition, levels=c("1", "2"), labels=c("Dyads", "Individuals"))
Data$subject[Data$condition=='Dyad']=as.factor(as.numeric(Data$subject[Data$condition=='Dyad']+30))
Data$subject=as.factor(Data$subject)
Data$session=as.numeric(Data$session)
Data$cycle=as.numeric(Data$cycle)
Data$cycle[Data$cycle==0]=4
Data$trial=as.numeric(Data$trial)
Data$test=as.factor(Data$test)
Data$stimulus=as.factor(Data$stimulus)
Data$category=as.factor(Data$category)
Data$response=as.factor(Data$response)
Data$dangerous=as.factor(Data$dangerous)
Data$nutricious=as.factor(Data$nutricious)
Data$correct=as.factor(Data$correct)
Data$cumulative=as.numeric(Data$cumulative)
Data$RT=as.numeric(Data$RT)
Data$motivation=as.numeric(Data$motivation)
Data$competence=as.numeric(Data$competence)
Data$communication=as.numeric(Data$communication)
Data$complement=as.numeric(Data$complement)
Data <- within(Data, condition <- relevel(condition, ref = 'Individuals'))
```

# Load a couple of additional functions (SEs, bootstrap and diagnostics)

```{r Functions, echo=F, warning=F, message=F}

# Loading a couple of functions to calculate standard errors
# The functions have been taken from the R cookbook: http://www.cookbook-r.com/Graphs/Plotting_means_and_error_bars_(ggplot2)/

summarySE <- function(data=NULL, measurevar, groupvars=NULL, na.rm=FALSE,
                      conf.interval=.95, .drop=TRUE) {
        require(plyr)
        
        # New version of length which can handle NA's: if na.rm==T, don't count them
        length2 <- function (x, na.rm=FALSE) {
                if (na.rm) sum(!is.na(x))
                else       length(x)
                }
        
        # This does the summary. For each group's data frame, return a vector with
        # N, mean, and sd
        datac <- ddply(data, groupvars, .drop=.drop,
                       .fun = function(xx, col) {
                               c(N    = length2(xx[[col]], na.rm=na.rm),
                                 mean = mean   (xx[[col]], na.rm=na.rm),
                                 sd   = sd     (xx[[col]], na.rm=na.rm)
                                 )
                               },
                       measurevar
                       )
        
        # Rename the "mean" column    
        datac <- rename(datac, c("mean" = measurevar))
        
        datac$se <- datac$sd / sqrt(datac$N)  # Calculate standard error of the mean
        
        # Confidence interval multiplier for standard error
        # Calculate t-statistic for confidence interval: 
        # e.g., if conf.interval is .95, use .975 (above/below), and use df=N-1
        ciMult <- qt(conf.interval/2 + .5, datac$N-1)
        datac$ci <- datac$se * ciMult
        
        return(datac)
        }

summarySEwithin <- function(data=NULL, measurevar, betweenvars=NULL, withinvars=NULL,
                            idvar=NULL, na.rm=FALSE, conf.interval=.90, .drop=TRUE) {
        
        # Ensure that the betweenvars and withinvars are factors
        factorvars <- vapply(data[, c(betweenvars, withinvars), drop=FALSE],
                             FUN=is.factor, FUN.VALUE=logical(1))
        
        if (!all(factorvars)) {
                nonfactorvars <- names(factorvars)[!factorvars]
                message("Automatically converting the following non-factors to factors: ",
                        paste(nonfactorvars, collapse = ", "))
                data[nonfactorvars] <- lapply(data[nonfactorvars], factor)
                }
        
        # Get the means from the un-normed data
        datac <- summarySE(data, measurevar, groupvars=c(betweenvars, withinvars),
                           na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
        
        # Drop all the unused columns (these will be calculated with normed data)
        datac$sd <- NULL
        datac$se <- NULL
        datac$ci <- NULL
        
        # Norm each subject's data
        ndata <- normDataWithin(data, idvar, measurevar, betweenvars, na.rm, .drop=.drop)
        
        # This is the name of the new column
        measurevar_n <- paste(measurevar, "_norm", sep="")
        
        # Collapse the normed data - now we can treat between and within vars the same
        ndatac <- summarySE(ndata, measurevar_n, groupvars=c(betweenvars, withinvars),
                            na.rm=na.rm, conf.interval=conf.interval, .drop=.drop)
        
        # Apply correction from Morey (2008) to the standard error and confidence interval
        #  Get the product of the number of conditions of within-S variables
        nWithinGroups    <- prod(vapply(ndatac[,withinvars, drop=FALSE], FUN=nlevels,
                                        FUN.VALUE=numeric(1)))
        correctionFactor <- sqrt( nWithinGroups / (nWithinGroups-1) )
        
        # Apply the correction factor
        ndatac$sd <- ndatac$sd * correctionFactor
        ndatac$se <- ndatac$se * correctionFactor
        ndatac$ci <- ndatac$ci * correctionFactor
        
        # Combine the un-normed means with the normed results
        merge(datac, ndatac)
        }

normDataWithin <- function(data=NULL, idvar, measurevar, betweenvars=NULL,
                           na.rm=FALSE, .drop=TRUE) {
        require(plyr)
        
        # Measure var on left, idvar + between vars on right of formula.
        data.subjMean <- ddply(data, c(idvar, betweenvars), .drop=.drop,
                               .fun = function(xx, col, na.rm) {
                                       c(subjMean = mean(xx[,col], na.rm=na.rm))
                                       },
                               measurevar,
                               na.rm
                               )
        
        # Put the subject means with original data
        data <- merge(data, data.subjMean)
        
        # Get the normalized data in a new column
        measureNormedVar <- paste(measurevar, "_norm", sep="")
        data[,measureNormedVar] <- data[,measurevar] - data[,"subjMean"] +
                mean(data[,measurevar], na.rm=na.rm)
        
        # Remove this subject mean column
        data$subjMean <- NULL
        
        return(data)
}

# Loading a function to calculate and report relevant properties of the statistical models

ModelDiagnostics <- function(model,linear=F){
  # Calculating the p-value of the single factors
  coefs = data.frame(coef(summary(model))) 
  if (linear==T){
    coefs$p = format.pval(2*(1-pnorm(abs(coefs$t.value))), digits=2, eps=0.0001) 
  }
  # Calculating the R2s of the model
  r2=r.squaredGLMM(model)
  
  if (AssumptionTesting==T){
    #Testing for influential observations
    alt.est <- influence(model, group="Child.ID")
    SigChange <- sigtest(alt.est, test=-1.96)$condition
    if ('TRUE' %in% SigChange$Changed.Sig){
      cat("WARNING! The model is not robust!")
      match('TRUE',SigChange$Changed.Sig)
    } else { cat('All good the model is robust')}
    
    plot(model)
    qqnorm(resid(model))
    hist(resid(model))
  }
  
  Preds=row.names(coefs)
  
  txt=sprintf("R2m = %.2f, R2 = %.2f \n", r2[1], r2[2])
  cat(txt)
  
  for (i in c(2:length(coefs[,1]))){
    if (linear==T){
    txt=sprintf("%s: β = %.2f, SE = %.2f, t-stat = %.2f, p = %s \n", Preds[i], coefs[i,1], coefs[i,2], coefs[i,4], coefs[i,5])}
    else{
      txt=sprintf("%s: β = %.2f, SE = %.2f, t-stat = %.2f, p = %s \n", Preds[i], coefs[i,1], coefs[i,2], coefs[i,3], coefs[i,4])}
    cat(txt)
  }
}

# Loading a function to bootstrap means
boot.mean<-function(data,d)
{  return(mean(data[d],na.rm=T)) }

```

### Analysis 1 - Performance (correctness) as a function of condition (individual vs dyad) and complexity (session)

N.B. We are excluding the post-test performance (rule-testing)

We use a mixed logistic regression model to assess main effects of condition (pair vs. individual) and complexity (session 1 to 3). We remove individual variability (random intercept plus random slopes due to session) and stimulus variability (random intercepts).

### The first model tests main effects

```{r TrainingMainEffects, echo=F, warning=F, message=F}

model1 <- glmer(correct~condition+session+(1+session|subject)+(1+condition+session|stimulus),family="binomial", Data[Data$test==0,],nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))

ModelDiagnostics(model1)

```

### The second model tests interaction effects

```{r TrainingInteractions, echo=F, warning=F, message=F}
model2 <- glmer(correct~condition*session+(1+session|subject)+(1+condition+session|stimulus), family="binomial",Data[Data$test==0,],nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))
# Creating the null model for getting a p-value
# Calculating the p-value of the single factors
p=anova(model1,model2)
p
ModelDiagnostics(model2)

```

### Plotting the best model (interaction effects)

```{r TrainingPlot, echo=F, warning=F, message=F}

Data$correct=as.numeric(Data$correct)
Data$correct=Data$correct-1

Data$fit[Data$test==0]=fitted(model2)
sum1 <- summarySEwithin(Data[Data$test==0,], measurevar="correct", withinvars=c("condition","session"), idvar="subject")

p1=ggplot(sum1, aes(x = session, y = correct, color=condition)) + #
        geom_errorbar(aes(ymin=correct-ci, ymax=correct+ci), colour="black", width=.1) +
        geom_line(aes(group=condition)) +
        geom_point(size=3, shape=21, fill="white") +  # 21 is filled circle
        theme_classic()+
        theme(legend.title=element_blank()) + 
        theme(legend.justification=c(1,1), legend.position=c(1,1)) +
        theme(legend.text=element_text(size=14))

p1

Data$correct=as.factor(Data$correct)

```

### Post-hoc tests
Given the interaction effects, we now do post-hoc testing to figure out what generates the interactions.
The mixed effects model corresponds to an ANOVA

```{r TrainingPostHoc, echo=F, warning=F, message=F}

Data$session=as.factor(Data$session)
Data$correct=as.factor(Data$correct)

model3 <- glmer(correct~condition*session+(1+session|subject)+(1+condition+session|stimulus), Data[Data$test==0,],family="binomial",nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))

ModelDiagnostics(model3)

Data$session=as.numeric(Data$session)

```

### Bootstrapping estimates

```{r TrainingBootstrap, echo=F, warning=F, message=F}

# First estimating overall pair vs. individual performance
Data$correct=as.numeric(Data$correct)-1
IndTrain = boot(Data$correct[Data$condition=='Individuals' & Data$test==0],statistic=boot.mean,R=10000)

IndCiTrain=boot.ci(IndTrain,type="bca")

DyaTrain = boot(Data$correct[Data$condition=='Dyads' & Data$test==0],statistic=boot.mean,R=10000)
DyaTrain
DyaCiTrain = boot.ci(boot.out=DyaTrain,type="bca")

# Second estimating performance by session

S1Train = boot(Data$correct[Data$session==1 & Data$test==0],statistic=boot.mean,R=10000)
S1TrainCi = boot.ci(boot.out=S1Train,type="bca")

S2Train = boot(Data$correct[Data$session==2 & Data$test==0],statistic=boot.mean,R=10000)
S2TrainCi = boot.ci(boot.out=S2Train,type="bca")

S3Train = boot(Data$correct[Data$session==3 & Data$test==0],statistic=boot.mean,R=10000)
S3TrainCi = boot.ci(boot.out=S3Train,type="bca")

# Finally looking at the third session only
S3Ind = boot(Data$correct[Data$session==3 & Data$condition=='Individuals' & Data$test==0],statistic=boot.mean,R=10000)
S3IndCi = boot.ci(boot.out=S3Ind,type="bca")

# Finally looking at the third session only
S3Dya = boot(Data$correct[Data$session==3 & Data$condition=='Dyads' & Data$test==0],statistic=boot.mean,R=10000)
S3DyaCi = boot.ci(boot.out=S3Dya,type="bca")

```

### Analysis 2 - Test Performance (correctness) as a function of condition (individual vs dyad) and complexity (session)

We use a mixed logistic regression model to assess main effects of condition (pair vs. individual) and complexity (session 1 to 3). We remove individual variability (random intercept plus random slopes due to session) and stimulus variability (random intercepts).

### The first model tests main effects

```{r TestMainEffects, echo=F, warning=F, message=F}

model1 <- glmer(correct~condition+session+(1+session|subject)+(1+condition+session|stimulus),Data[Data$test==1,],family="binomial",nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))

ModelDiagnostics(model1)

```

### The second model tests interaction effects

```{r TestInteractions, echo=F, warning=F, message=F}
Data$correct=as.factor(Data$correct)

model2 <- glmer(correct~condition*session+(1+session|subject)+(1+condition+session|stimulus),Data[Data$test==1,],family="binomial",nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))

p=anova(model1,model2)
p

ModelDiagnostics(model2)

```

### Plotting the best model (interaction effects)

```{r TestPlot, echo=F, warning=F, message=F}
Data$correct=as.numeric(Data$correct)
Data$correct=Data$correct-1

Data$fit[Data$test==1]=fitted(model2)
sum1 <- summarySEwithin(Data[Data$test==1,], measurevar="correct", withinvars=c("condition","session"), idvar="subject")

p1=ggplot(sum1, aes(x = session, y = correct, color=condition)) + #
        geom_errorbar(aes(ymin=correct-ci, ymax=correct+ci), colour="black", width=.1) +
        geom_line(aes(group=condition)) +
        geom_point(size=3, shape=21, fill="white") +  # 21 is filled circle
        theme_classic()+
        theme(legend.title=element_blank()) + 
        theme(legend.justification=c(1,1), legend.position=c(1,1)) +
        theme(legend.text=element_text(size=14))

p1
Data$correct=as.factor(Data$correct)
```

### Post-hoc testing

Given the interaction effects, we now do post-hoc testing to figure out what generates the interactions.
The mixed effects model corresponds to an ANOVA

```{r TestPostHoc, echo=F, warning=F, message=F}
# Post Hoc testing
Data$session=as.factor(Data$session)
Data$correct=as.factor(Data$correct)

model3 <- glmer(correct~condition*session+(1+session|subject)+(1+session+condition|stimulus), Data[Data$test==1,],family="binomial",nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))

ModelDiagnostics(model3)

model4 <- glmer(correct~session+(1+session|subject)+(1+session|stimulus), Data[Data$test==1 & Data$condition=='Individuals',],family="binomial",nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))

ModelDiagnostics(model4)

model5 <- glmer(correct~session+(1+session|subject)+(1+session|stimulus), Data[Data$test==1 & Data$condition=='Dyads',],family="binomial",nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))

ModelDiagnostics(model5)

Data$session=as.numeric(Data$session)

```

### Bootstrapping estimates

```{r TestBootstrap, echo=F, warning=F, message=F}
Data$correct=as.numeric(Data$correct)-1

IndTest = boot(Data$correct[Data$condition=='Individuals' & Data$test==1],statistic=boot.mean,R=10000)

IndCiTest=boot.ci(IndTest,type="bca")

DyaTest = boot(Data$correct[Data$condition=='Dyads' & Data$test==1],statistic=boot.mean,R=10000)
DyaCiTest = boot.ci(boot.out=DyaTest,type="bca")

S1Test = boot(Data$correct[Data$session==1 & Data$test==1],statistic=boot.mean,R=10000)
S1TestCi = boot.ci(boot.out=S1Test,type="bca")

S2Test = boot(Data$correct[Data$session==2 & Data$test==1],statistic=boot.mean,R=10000)
S2TestCi = boot.ci(boot.out=S2Test,type="bca")

S3Test = boot(Data$correct[Data$session==3 & Data$test==1],statistic=boot.mean,R=10000)
S3TestCi = boot.ci(boot.out=S3Test,type="bca")
```

## Analysis 3

Extracting learning curve from each participant/dyad and predicting:

- condition (do dyads and participants have different learning curves?)

  . also by first cycle only

- post-test performance (does learning curve reflect rule learning?)

### Prepare the data

```{r LearningPreprocess, echo=F, warning=F, message=F}

n=1
condition=""
session=0
subject=""
intercept=0
slope=0
slope2=0
conditionC=""
sessionC=0
subjectC=""
interceptC=0
slopeC=0
slope2C=0
testPerf=0
testPerf2=0
Data$trial2=Data$trial^2
# Create the learning curve dataset
for (k in unique(Data$condition)){
for (i in unique(Data$subject)) {
  for (l in unique(Data$session)){
    x=Data[Data$test==0 & Data$session==l & Data$subject==i & Data$condition==k,]
    xc=Data[Data$test==0 & Data$session==l & Data$subject==i & Data$condition==k & Data$cycle==1,]
    if (nrow(x)>0) {
   
      model1 <- glmer(correct~trial+(1|stimulus), x,family="binomial",nAGQ=0, control=glmerControl(optimizer = "nloptwrap")) 
     modelC <- glmer(correct~trial+(1|stimulus), xc,family="binomial",nAGQ=0, control=glmerControl(optimizer = "nloptwrap")) 
    
    condition[n]=x$condition[1]
    subject[n]=i
    session[n]=l
    intercept[n] =fixef(model1)[1]
    slope[n] =fixef(model1)[2]
    
    conditionC[n]=xc$condition[1]
    subjectC[n]=i
    sessionC[n]=l
    interceptC[n] =fixef(modelC)[1]
    slopeC[n] =fixef(modelC)[2]
    
    x1=Data[Data$test==1 & Data$session==l & Data$subject==i & Data$condition==k,]
    testPerf[n]=sum(as.numeric(x1$correct))
    testPerf2[n]=testPerf[n]/nrow(x)
    n=n+1
    
    }
  }
}
}

LearningSet=data.frame(condition,subject,session,intercept,slope,testPerf,testPerf2)
LearningSetC=data.frame(conditionC,subjectC,sessionC,interceptC,slopeC,testPerf,testPerf2)
```

### Predicting condition from learning curve

Main Effects first and Interaction second

```{r LearningPredictingCondition, echo=F, warning=F, message=F}

model2=glmer(condition ~ intercept + slope  + session + (1 + session | subject), LearningSet, family="binomial",nAGQ=0, control=glmerControl(optimizer = "nloptwrap")) 

ModelDiagnostics(model2)

model3=glmer(condition ~ (intercept + slope)  * session + (1 + session | subject), LearningSet, family="binomial",nAGQ=0, control=glmerControl(optimizer = "nloptwrap")) #+ slope2

ModelDiagnostics(model3)
```


### Predicting condition from learning curve in first cycle

```{r LearningFirstCyclePredictingCondition, echo=F, warning=F, message=F}
model2C=glmer(as.factor(condition) ~ interceptC + slopeC  + sessionC + (1 + sessionC | subjectC), LearningSetC, family="binomial", nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))#+ slope2C

ModelDiagnostics(model2C)

model3C=glmer(as.factor(condition) ~ (interceptC + slopeC)  * sessionC + (1 + sessionC | subjectC), LearningSetC, family="binomial", nAGQ=0, control=glmerControl(optimizer = "nloptwrap"))#+ slope2C

ModelDiagnostics(model3C)

```

### Predicting test performance from learning curve

```{r LearningPredictingTest, echo=F, warning=F, message=F}
#model4=glmer(testPerf ~ intercept + slope  + condition + session + (1 + condition + session | subject), LearningSet,family='poisson')

model4=glmer(testPerf ~ intercept + slope + condition + (1 + condition | subject), LearningSet,family='poisson')


ModelDiagnostics(model4)

fit=fitted(model4)

plot4= ggplot(LearningSet,aes(fit,testPerf)) + geom_point()+ stat_smooth(method = "lm")+theme_classic()
plot4

```

### Bootstrapping estimates

```{r LearningBootstrap, echo=F, warning=F, message=F}

IndIntercept = boot(LearningSet$intercept[LearningSet$condition=="1"],statistic=boot.mean,R=10000)
IndInterceptCi = boot.ci(boot.out=IndIntercept,type="bca")

DyaIntercept = boot(LearningSet$intercept[LearningSet$condition=="2"],statistic=boot.mean,R=10000)
DyaInterceptCi = boot.ci(boot.out=DyaIntercept,type="bca")

IndSlope = boot(LearningSet$slope[LearningSet$condition=="1"],statistic=boot.mean,R=10000)
IndSlopeCi = boot.ci(boot.out=IndSlope,type="bca")

DyaSlope = boot(LearningSet$slope[LearningSet$condition=="2"],statistic=boot.mean,R=10000)
DyaSlopeCi = boot.ci(boot.out=DyaSlope,type="bca")

```

## Self-reported effort and motivation by condition

### Loading Data

```{r SurveyData}
Data=read.csv('AlienSurvey.csv', sep=",", header=TRUE) # Name of the file

Data$Pair[Data$Condition=='Individuals']=Data$Pair[Data$Condition=='Individuals']+26
Data$Subject=(Data$Pair*10)+Data$Subject
Data$Pair=factor(Data$Pair)
Data$Subject=factor(Data$Subject)
Data$Condition=factor(Data$Condition)

```

### Contrasting effort and motivation in dyads and individuals

```{r SurveyTest}

model1=lmer(Response~Condition+(1|Pair),REML=F,Data[Data$Question==3,])
ModelDiagnostics(model1,linear=T)

by(Data$Response[Data$Question==3],Data$Condition[Data$Question==3],stat.desc)

model2=lmer(Response~Condition+(1|Pair),REML=F,Data[Data$Question==4,])
ModelDiagnostics(model2,linear=T)

by(Data$Response[Data$Question==4],Data$Condition[Data$Question==4],stat.desc)

```